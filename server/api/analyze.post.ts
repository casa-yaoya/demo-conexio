// File analysis endpoint - Analyzes uploaded files using AI (OpenAI only)
import { readMultipartFormData } from 'h3'
import OpenAI from 'openai'

interface AnalysisResult {
  success: boolean
  text?: string
  pages?: Array<{ pageNumber: number; content: string }>
  error?: string
}

// Lazy initialize client to avoid startup errors when API key is not set
let openaiClient: OpenAI | null = null

function getOpenAI(): OpenAI {
  if (!openaiClient) {
    const config = useRuntimeConfig()
    openaiClient = new OpenAI({
      apiKey: config.openaiApiKey || process.env.NUXT_OPENAI_API_KEY || ''
    })
  }
  return openaiClient
}

export default defineEventHandler(async (event): Promise<AnalysisResult> => {
  console.log('ğŸ” Analyze API called')

  try {
    const formData = await readMultipartFormData(event)

    if (!formData || formData.length === 0) {
      return { success: false, error: 'No file provided' }
    }

    const fileData = formData.find(item => item.filename)
    const fileTypeField = formData.find(item => item.name === 'fileType')
    const selectedRangeField = formData.find(item => item.name === 'selectedRange')

    if (!fileData || !fileData.filename || !fileData.data) {
      return { success: false, error: 'Invalid file data' }
    }

    const fileType = fileTypeField?.data?.toString() || 'unknown'
    const filename = fileData.filename
    const buffer = fileData.data

    // Parse selected range if provided
    let selectedRange: number[] = []
    if (selectedRangeField?.data) {
      try {
        selectedRange = JSON.parse(selectedRangeField.data.toString())
      } catch {
        selectedRange = []
      }
    }

    console.log(`ğŸ“„ Analyzing file: ${filename}, type: ${fileType}, size: ${buffer.length}`)
    if (selectedRange.length > 0) {
      console.log(`ğŸ“Š Selected pages/range: ${selectedRange.join(', ')}`)
    }

    // Route to appropriate analyzer based on file type
    if (fileType === 'pdf' || filename.toLowerCase().endsWith('.pdf')) {
      return await analyzePDF(buffer, filename, selectedRange)
    } else if (fileType === 'audio' || isAudioFile(filename)) {
      return await analyzeAudio(buffer, filename)
    } else if (fileType === 'video' || isVideoFile(filename)) {
      return await analyzeVideo(buffer, filename)
    } else {
      return { success: false, error: `Unsupported file type: ${fileType}` }
    }

  } catch (error) {
    console.error('âŒ Analysis error:', error)
    return {
      success: false,
      error: error instanceof Error ? error.message : 'Analysis failed'
    }
  }
})

// Check if file is audio
function isAudioFile(filename: string): boolean {
  const audioExtensions = ['.mp3', '.wav', '.m4a', '.ogg', '.flac', '.aac']
  return audioExtensions.some(ext => filename.toLowerCase().endsWith(ext))
}

// Check if file is video
function isVideoFile(filename: string): boolean {
  const videoExtensions = ['.mp4', '.mov', '.avi', '.webm', '.mkv']
  return videoExtensions.some(ext => filename.toLowerCase().endsWith(ext))
}

// Analyze PDF using OpenAI Vision
async function analyzePDF(buffer: Buffer, filename: string, selectedPages: number[] = []): Promise<AnalysisResult> {
  console.log('ğŸ“‘ Analyzing PDF with OpenAI Vision...')
  if (selectedPages.length > 0) {
    console.log(`ğŸ“Š Extracting only pages: ${selectedPages.join(', ')}`)
  }

  try {
    // Convert PDF pages to images using pdf-lib and canvas
    // For now, send the PDF as base64 directly (OpenAI can process PDF)
    const base64PDF = buffer.toString('base64')

    // Build prompt based on selected pages
    let promptText: string
    if (selectedPages.length > 0) {
      const pageList = selectedPages.join(', ')
      promptText = `ã“ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã€æŒ‡å®šã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã®ã¿ã®å†…å®¹ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã€æŠ½å‡ºå¯¾è±¡ãƒšãƒ¼ã‚¸ã€‘: ${pageList}

è¦ä»¶ï¼š
1. ä¸Šè¨˜ã§æŒ‡å®šã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã®ã¿ã‚’æŠ½å‡ºã€‚ä»–ã®ãƒšãƒ¼ã‚¸ã¯ç„¡è¦–
2. ãƒ†ã‚­ã‚¹ãƒˆã¯å…ƒã®é…ç½®ãƒ»é †åºã‚’ä¿æŒ
3. è¡¨ã¯æ§‹é€ ã‚’ä¿æŒã—ã¦è¨˜è¿°ï¼ˆãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼æ¨å¥¨ï¼‰
4. å›³ã‚„ã‚°ãƒ©ãƒ•ãŒã‚ã‚‹å ´åˆã€ãã®å†…å®¹ã‚’èª¬æ˜
5. æ•°å­—ã‚„é‡‘é¡ã¯æ­£ç¢ºã«æŠ½å‡º
6. è¦‹å‡ºã—ã‚„é …ç›®åã¯æ˜ç¢ºã«åŒºåˆ¥
7. å„ãƒšãƒ¼ã‚¸ã¯ã€Œ=== ãƒšãƒ¼ã‚¸ N ===ã€ã§åŒºåˆ‡ã‚Š

æ—¥æœ¬èªã®æ–‡å­—ã¯å…¨ã¦æ­£ç¢ºã«æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚æŒ‡å®šãƒšãƒ¼ã‚¸ä»¥å¤–ã®å†…å®¹ã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚`
    } else {
      promptText = `ã“ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’å…¨ã¦æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

è¦ä»¶ï¼š
1. ãƒ†ã‚­ã‚¹ãƒˆã¯å…ƒã®é…ç½®ãƒ»é †åºã‚’ä¿æŒ
2. è¡¨ã¯æ§‹é€ ã‚’ä¿æŒã—ã¦è¨˜è¿°ï¼ˆãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼æ¨å¥¨ï¼‰
3. å›³ã‚„ã‚°ãƒ©ãƒ•ãŒã‚ã‚‹å ´åˆã€ãã®å†…å®¹ã‚’èª¬æ˜
4. æ•°å­—ã‚„é‡‘é¡ã¯æ­£ç¢ºã«æŠ½å‡º
5. è¦‹å‡ºã—ã‚„é …ç›®åã¯æ˜ç¢ºã«åŒºåˆ¥
6. ãƒšãƒ¼ã‚¸ã”ã¨ã«ã€Œ=== ãƒšãƒ¼ã‚¸ N ===ã€ã§åŒºåˆ‡ã‚Š

æ—¥æœ¬èªã®æ–‡å­—ã¯å…¨ã¦æ­£ç¢ºã«æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚`
    }

    // Use OpenAI to analyze the PDF
    const response = await getOpenAI().chat.completions.create({
      model: 'gpt-4o',
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'file',
              file: {
                filename: filename,
                file_data: `data:application/pdf;base64,${base64PDF}`
              }
            } as any,
            {
              type: 'text',
              text: promptText
            }
          ]
        }
      ],
      max_tokens: 16000
    })

    const content = response.choices[0]?.message?.content || ''
    console.log('âœ… PDF analysis complete')

    return {
      success: true,
      text: content
    }
  } catch (error) {
    console.error('PDF analysis error:', error)

    // Fallback: return placeholder
    return {
      success: true,
      text: `[PDF FILE: ${filename}] - OpenAI Visionåˆ†æã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: ${Math.round(buffer.length / 1024)} KB`
    }
  }
}

// Analyze audio using OpenAI Whisper
async function analyzeAudio(buffer: Buffer, filename: string): Promise<AnalysisResult> {
  console.log('ğŸµ Analyzing audio with OpenAI Whisper...')

  try {
    const mimeType = getMimeType(filename)
    const file = new File([buffer], filename, { type: mimeType })

    // Send to Whisper API for transcription
    const transcription = await getOpenAI().audio.transcriptions.create({
      file: file,
      model: 'whisper-1',
      language: 'ja'
    })

    console.log('âœ… Audio transcription complete via Whisper')

    return {
      success: true,
      text: transcription.text
    }
  } catch (error) {
    console.error('Audio analysis error:', error)
    return {
      success: false,
      error: `éŸ³å£°è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'Unknown error'}`
    }
  }
}

// Analyze video using Whisper API
// å‡¦ç†ID: FILE-006
// Note: For large videos, client-side FFmpeg processing is recommended
async function analyzeVideo(buffer: Buffer, filename: string): Promise<AnalysisResult> {
  console.log('ğŸ¬ Analyzing video with Whisper API...')

  try {
    // Create a File object from buffer for Whisper API
    const mimeType = getMimeType(filename)
    const file = new File([buffer], filename, { type: mimeType })

    // Send to Whisper API for transcription
    const transcription = await getOpenAI().audio.transcriptions.create({
      file: file,
      model: 'whisper-1',
      language: 'ja'
    })

    console.log('âœ… Video transcription complete via Whisper')

    return {
      success: true,
      text: transcription.text
    }
  } catch (error) {
    console.error('Video analysis error:', error)
    return {
      success: false,
      error: `å‹•ç”»è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'Unknown error'}`
    }
  }
}

// Get MIME type from filename
function getMimeType(filename: string): string {
  const ext = filename.toLowerCase().split('.').pop()
  const mimeTypes: Record<string, string> = {
    'mp3': 'audio/mpeg',
    'wav': 'audio/wav',
    'm4a': 'audio/m4a',
    'ogg': 'audio/ogg',
    'flac': 'audio/flac',
    'aac': 'audio/aac',
    'mp4': 'video/mp4',
    'mov': 'video/quicktime',
    'avi': 'video/x-msvideo',
    'webm': 'video/webm',
    'mkv': 'video/x-matroska',
    'pdf': 'application/pdf'
  }
  return mimeTypes[ext || ''] || 'application/octet-stream'
}
